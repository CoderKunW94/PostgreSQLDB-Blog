## 穷鬼玩PolarDB RAC一写多读集群系列 | 计算节点 Switchover        
          
### 作者      
digoal          
          
### 日期          
2024-12-18          
          
### 标签          
PostgreSQL , PolarDB , DuckDB , docker , Switchover , promote replica   
          
----          
          
## 背景          
穷鬼玩PolarDB RAC一写多读集群系列已经写了3篇:   
- [《在Docker容器中用loop设备模拟共享存储》](../202412/20241216_03.md)   
- [《如何搭建PolarDB容灾(standby)节点》](../202412/20241218_01.md) .     
- [《共享存储在线扩容》](../202412/20241218_02.md)     
  
本篇文章介绍一下如何进行PolarDB计算节点的Switchover?  实验环境依赖 [《在Docker容器中用loop设备模拟共享存储》](../202412/20241216_03.md) , 如果没有环境, 请自行参考以上文章搭建环境.       
    
还需要参考如下文档:          
- https://apsaradb.github.io/PolarDB-for-PostgreSQL/zh/operation/ro-online-promote.html  
        
## DEMO        
<b> 只有当 Primary 节点停止写入后，才可以将 Replica 节点提升为 Primary 节点，否则将会出现集群内多个节点同时写入存储的情况。当数据库检测到出现多节点写入时，将会导致运行异常。</b>    
  
1、停止p1 primary  
```  
# 进入pb1容器  
docker exec -ti pb1 bash  
  
# 停止primary  
pg_ctl stop -m fast -D ~/primary  
  
日志如下:   
waiting for server to shut down.... done  
server stopped  
```  
  
2、promote p2 replica   
```  
# 进入pb2容器  
docker exec -ti pb2 bash  
  
# promote replica  
pg_ctl promote -D ~/replica1  
```  
  
出现报错如下:  
```  
[PFSD_SDK INF Dec 18 14:33:38.327335][859]pfsd_umount_force 247: pbdname nvme1n1  
[PFSD_SDK INF Dec 18 14:33:38.330154][859]chnl_connection_release_shm 1164: client umount return : deleted /var/run/pfsd//nvme1n1/859.pid  
[PFSD_SDK INF Dec 18 14:33:38.330163][859]pfsd_umount_force 261: umount success for nvme1n1  
waiting for server to promote...[PFSD_SDK INF Dec 18 14:33:38.444794][859]pfsd_umount_force 247: pbdname nvme1n1  
[PFSD_SDK INF Dec 18 14:33:38.446306][859]chnl_connection_release_shm 1164: client umount return : deleted /var/run/pfsd//nvme1n1/859.pid  
[PFSD_SDK INF Dec 18 14:33:38.446314][859]pfsd_umount_force 261: umount success for nvme1n1  
.[PFSD_SDK INF Dec 18 14:33:38.690673][859]pfsd_umount_force 247: pbdname nvme1n1  
[PFSD_SDK INF Dec 18 14:33:38.693022][859]chnl_connection_release_shm 1164: client umount return : deleted /var/run/pfsd//nvme1n1/859.pid  
[PFSD_SDK INF Dec 18 14:33:38.693035][859]pfsd_umount_force 261: umount success for nvme1n1  
[PFSD_SDK INF Dec 18 14:33:38.917831][859]pfsd_umount_force 247: pbdname nvme1n1  
[PFSD_SDK INF Dec 18 14:33:38.919652][859]chnl_connection_release_shm 1164: client umount return : deleted /var/run/pfsd//nvme1n1/859.pid  
[PFSD_SDK INF Dec 18 14:33:38.919664][859]pfsd_umount_force 261: umount success for nvme1n1  
[PFSD_SDK INF Dec 18 14:33:39.364163][859]pfsd_umount_force 247: pbdname nvme1n1  
[PFSD_SDK INF Dec 18 14:33:39.390100][859]chnl_connection_release_shm 1164: client umount return : deleted /var/run/pfsd//nvme1n1/859.pid  
[PFSD_SDK INF Dec 18 14:33:39.390109][859]pfsd_umount_force 261: umount success for nvme1n1  
 stopped waiting  
pg_ctl: server did not promote in time  
```  
  
数据库日志如下:  
```  
$PGDATA/pg_log/postgresql-2024-12-18_142905_error.log  
  
849			2024-12-18 14:33:38.330 CST	LOG:  received promote request  
849			2024-12-18 14:33:38.330 CST	LOG:  async lock replay: startup@polar_alr_terminate_worker: terminate worker  
849			2024-12-18 14:33:38.333 CST	LOG:  redo done at 0/484CAF88 system usage: CPU: user: 0.00 s, system: 0.00 s, elapsed: 263.78 s  
849			2024-12-18 14:33:38.333 CST	LOG:  last completed transaction was at log time 2024-12-18 14:29:14.656403+08  
849			2024-12-18 14:33:38.333 CST	WARNING:  polar_log_read_record read records from 'currRecPtr: 0/484C5168, read record: (0/484C5168, 0/484C51E0), decoded record: (0/484C5168, 0/484C51E0, 0/0)' to 'currRecPtr: 0/484CAF88, read record: (0/484CAF88, 0/484CB000), decoded record: (0/484CAF88, 0/484CB000, 0/0)', next record is 'currRecPtr: 0/484CAF88, read record: (0/484CAF88, 0/484CB000), decoded record: (0/484CAF88, 0/484CB000, 0/0)'  
849			2024-12-18 14:33:38.380 CST	WARNING:  replica can't modify file in shared storage by pfs: /nvme1n1/shared_data//base/5  
849			2024-12-18 14:33:38.424 CST	WARNING:  replica can't modify file in shared storage by pfs: /nvme1n1/shared_data//base/1  
849			2024-12-18 14:33:38.465 CST	WARNING:  replica can't modify file in shared storage by pfs: /nvme1n1/shared_data//base/4  
849			2024-12-18 14:33:38.509 CST	WARNING:  replica can't modify file in shared storage by pfs: /nvme1n1/shared_data//base/13572  
849			2024-12-18 14:33:38.509 CST	LOG:  selected new timeline ID: 2  
849			2024-12-18 14:33:38.511 CST	LOG:  vfs_unlink /nvme1n1/shared_data//pg_wal/xlogtemp.849  
Got coredump signal(11) in process(849)  
Process Info:  
  pid:	849  
  type:	startup  
  sql:	<NULL>  
Backtrace:  
  #0  polar_program_error_handler+0x388 [0xaaaad54f72a4]  
  #1  +0x388 [0xffffabc2d790]  
  #2  strerrordesc_np+0x1e30 [0xffffaac19950]  
  #3  dopr+0x164 [0xaaaad55824b0]  
  #4  pg_vsnprintf+0xa0 [0xaaaad5581c68]  
  #5  pvsnprintf+0x44 [0xaaaad5574e54]  
  #6  appendStringInfoVA+0xb4 [0xaaaad5576cb8]  
  #7  errmsg+0x1c4 [0xaaaad54ef674]  
  #8  polar_vfs_file_handle_node_type+0x158 [0xffffa77de3cc]  
  #9  polar_stat_file_before_hook+0x44 [0xffff933b5ef8]  
  #10 vfs_unlink+0xf0 [0xffffa77daa00]  
  #11 polar_unlink+0x4c [0xaaaad4e017bc]  
  #12 XLogFileCopy+0x130 [0xaaaad4e06f38]  
  #13 XLogInitNewTimeline+0xe4 [0xaaaad4e0acf4]  
  #14 StartupXLOG+0xcd0 [0xaaaad4e0bf68]  
  #15 StartupProcessMain+0xcc [0xaaaad51f49b4]  
  #16 AuxiliaryProcessMain+0x284 [0xaaaad51e2520]  
  #17 StartChildProcess+0x60 [0xaaaad51f27c0]  
  #18 PostmasterMain+0x1564 [0xaaaad51eb5bc]  
  #19 main+0x380 [0xaaaad50dde60]  
  #20 __libc_init_first+0x7c [0xffffaaba73fc]  
  #21 __libc_start_main+0x98 [0xffffaaba74cc]  
  #22 _start+0x30 [0xaaaad4cc1f70]  
851			2024-12-18 14:33:38.628 CST	WARNING:  Failed to get the instance memory usage  
836			2024-12-18 14:33:39.049 CST	LOG:  startup process (PID 849) was terminated by signal 11: Segmentation fault  
836			2024-12-18 14:33:39.049 CST	LOG:  terminating any other active server processes  
836			2024-12-18 14:33:39.051 CST	LOG:  shutting down due to startup process failure  
[PFSD_SDK INF Dec 18 14:33:39.051684][836]pfsd_umount_force 247: pbdname nvme1n1  
[PFSD_SDK INF Dec 18 14:33:39.072031][836]chnl_connection_release_shm 1164: client umount return : deleted /var/run/pfsd//nvme1n1/836.pid  
[PFSD_SDK INF Dec 18 14:33:39.072049][836]pfsd_umount_force 261: umount success for nvme1n1  
836			2024-12-18 14:33:39.072 CST	LOG:  umount pbd nvme1n1 success  
836			2024-12-18 14:33:39.103 CST	LOG:  database system is shut down  
```  
  
core文件bt如下:  
```  
$ gdb --exec=/home/postgres/tmp_polardb_pg_15_base/bin/postgres --core=/home/postgres/replica1/core  
GNU gdb (Ubuntu 12.1-0ubuntu1~22.04.2) 12.1  
Copyright (C) 2022 Free Software Foundation, Inc.  
License GPLv3+: GNU GPL version 3 or later <http://gnu.org/licenses/gpl.html>  
This is free software: you are free to change and redistribute it.  
There is NO WARRANTY, to the extent permitted by law.  
Type "show copying" and "show warranty" for details.  
This GDB was configured as "aarch64-linux-gnu".  
Type "show configuration" for configuration details.  
For bug reporting instructions, please see:  
<https://www.gnu.org/software/gdb/bugs/>.  
Find the GDB manual and other documentation resources online at:  
    <http://www.gnu.org/software/gdb/documentation/>.  
  
For help, type "help".  
Type "apropos word" to search for commands related to "word".  
  
warning: Can't open file /dev/zero (deleted) during file-backed mapping note processing  
  
warning: Can't open file /dev/shm/PostgreSQL.3630676106 during file-backed mapping note processing  
  
warning: Can't open file /SYSV000c289a (deleted) during file-backed mapping note processing  
[New LWP 849]  
[Thread debugging using libthread_db enabled]  
Using host libthread_db library "/lib/aarch64-linux-gnu/libthread_db.so.1".  
Core was generated by `postgres(5432): startup                                                      '.  
Program terminated with signal SIGSEGV, Segmentation fault.  
#0  __pthread_kill_implementation (threadid=281473559998496, signo=signo@entry=11, no_tid=no_tid@entry=0) at ./nptl/pthread_kill.c:44  
44	./nptl/pthread_kill.c: No such file or directory.  
(gdb) bt  
#0  __pthread_kill_implementation (threadid=281473559998496, signo=signo@entry=11, no_tid=no_tid@entry=0) at ./nptl/pthread_kill.c:44  
#1  0x0000ffffaabff254 in __pthread_kill_internal (signo=11, threadid=<optimized out>) at ./nptl/pthread_kill.c:78  
#2  0x0000ffffaabba67c in __GI_raise (sig=11) at ../sysdeps/posix/raise.c:26  
#3  0x0000aaaad54f74f0 in ?? ()  
#4  0x0000000b00000000 in ?? ()  
Backtrace stopped: previous frame identical to this frame (corrupt stack?)  
```  
   
在pb2 `sudo dmesg` 系统层面未看到oom或其他报错, 尝试了关闭其他容器(降低内存使用), 问题依旧.   
   
<b> 暂时无法进行后续操作, 请问有什么解决办法? </b>     

<b> 在研发同学帮助下, 已经找到问题并解决: 没有开启logindex, 导致ro无法被激活. 但是这个手册中没有提及, 期待未来官方文档的补充说明. 开启logindex配置几个参数即可, 参数已经更新到 [《在Docker容器中用loop设备模拟共享存储》](../202412/20241216_03.md) . 你跟着做的话, 应该不会碰到我的问题了. </b>  
  
promote 正常的日志如下:  
```
$ pg_ctl promote -D ~/replica1
[PFSD_SDK INF Dec 24 09:56:35.922139][747]pfsd_umount_force 247: pbdname nvme1n1
[PFSD_SDK INF Dec 24 09:56:35.923984][747]chnl_connection_release_shm 1164: client umount return : deleted /var/run/pfsd//nvme1n1/747.pid
[PFSD_SDK INF Dec 24 09:56:35.924002][747]pfsd_umount_force 261: umount success for nvme1n1
waiting for server to promote...[PFSD_SDK INF Dec 24 09:56:36.036961][747]pfsd_umount_force 247: pbdname nvme1n1
[PFSD_SDK INF Dec 24 09:56:36.038059][747]chnl_connection_release_shm 1164: client umount return : deleted /var/run/pfsd//nvme1n1/747.pid
[PFSD_SDK INF Dec 24 09:56:36.038070][747]pfsd_umount_force 261: umount success for nvme1n1
 done
server promoted
postgres@895e6aa6ffd4:~$ psql
psql (PostgreSQL 15.10 (PolarDB 15.10.2.0 build d4f5477d debug) on aarch64-linux-gnu)
Type "help" for help.

slot 也正常的切换了:  
postgres=# select * from pg_replication_slots;
 slot_name | plugin | slot_type | datoid | database | temporary | active | active_pid | xmin | catalog_xmin | restart_lsn | confirmed_flush_lsn | wal_status | safe_wal_size | two_phase 
-----------+--------+-----------+--------+----------+-----------+--------+------------+------+--------------+-------------+---------------------+------------+---------------+-----------
 replica1  |        | physical  |        |          | f         | f      |            |      |              | 0/40940E40  |                     | reserved   |               | f
 standby1  |        | physical  |        |          | f         | f      |            |      |              | 0/40942F38  |                     | reserved   |               | f
(2 rows)
```
  
3、配置p1 primary作为replica OR 重建1个replica.    
  
重建/新建 replica 参考: [《穷鬼玩PolarDB RAC一写多读集群系列 | 在Docker容器中用loop设备模拟共享存储》](../202412/20241216_03.md)    
  
假设是全新的计算节点(容器), 需要参考以上文章依次执行如下:    
- 部署PolarDB二进制. 参考步骤 <b> 9、将编译好的二进制拷贝到pb1, pb2的HOME目录, 便于调用 </b>
- 部署PFS二进制. 参考步骤 <b> 使用 polardb_pg_devel:ubuntu22.04 镜像, 自带pfs, 无需再安装pfs. </b>
- 接入共享块设备. 参考步骤 <b> 可以跳过步骤 : 5.1 和 5.2 </b>
- 将共享块设备软链到 nvme1n1. 参考步骤 <b> 5.3、将loop设备软链到nvme1n1 </b>  
- 启动 pfsd 参考步骤 <b> 7、在pb1, pb2都启动pfsd, -w为工作进程数量, 数字越大IO性能越好, 这里受制于容器资源限制设置为1. </b>
- 新增部署replica节点. 参考步骤 <b> 15、replica节点部署. </b> 及后续步骤  
  
  
## 参考    
[《穷鬼玩PolarDB RAC一写多读集群系列 | 在Docker容器中用loop设备模拟共享存储》](../202412/20241216_03.md)           
       
[《穷鬼玩PolarDB RAC一写多读集群系列 | 如何搭建PolarDB容灾(standby)节点》](../202412/20241218_01.md)     
  
[《穷鬼玩PolarDB RAC一写多读集群系列 | 共享存储在线扩容》](../202412/20241218_02.md)     
    
https://apsaradb.github.io/PolarDB-for-PostgreSQL/zh/operation/ro-online-promote.html  
  
  
#### [期望 PostgreSQL|开源PolarDB 增加什么功能?](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216")
  
  
#### [PolarDB 开源数据库](https://openpolardb.com/home "57258f76c37864c6e6d23383d05714ea")
  
  
#### [PolarDB 学习图谱](https://www.aliyun.com/database/openpolardb/activity "8642f60e04ed0c814bf9cb9677976bd4")
  
  
#### [PostgreSQL 解决方案集合](../201706/20170601_02.md "40cff096e9ed7122c512b35d8561d9c8")
  
  
#### [德哥 / digoal's Github - 公益是一辈子的事.](https://github.com/digoal/blog/blob/master/README.md "22709685feb7cab07d30f30387f0a9ae")
  
  
#### [About 德哥](https://github.com/digoal/blog/blob/master/me/readme.md "a37735981e7704886ffd590565582dd0")
  
  
![digoal's wechat](../pic/digoal_weixin.jpg "f7ad92eeba24523fd47a6e1a0e691b59")
  
