## 德说-第320期, 数据库服务器集成GPU不是目的, 数据库到底要提升什么能力?来更好的结合AI?   
                    
### 作者                    
digoal                    
                    
### 日期                    
2025-04-09                   
                    
### 标签                    
PostgreSQL , PolarDB , DuckDB , Data+AI , GPU , wire protocol , 被动请求 , random token url , 异步接口   
                    
----                    
                    
## 背景      
数据库服务器集成GPU一定不是好主意! 数据库到底要提升什么能力? 来更好的结合AI?   
  
1、数据库什么时候/场景要使用GPU, 使用GPU是高频操作吗? 频率如何?    
- 推理, 例如基于问题和数据, 让大模型进行推理. 也许能成为高频操作, 但是再看问题2.    
- RAG, 例如基于问题和记忆/相关知识点, 让大模型生成结果. 也许能成为高频操作, 但是再看问题2.   
- 预训练, 使用数据库存储预训练的数据集, 预训练的过程中进行调用. 低频操作, 这种场景要的是数据的大吞吐, 所以你看deepseek开源smallpod(base on duckdb)测的benchmark是什么? 大吞吐的数据进出.    
- 微调, 使用数据库存储微调的数据集, 微调的过程中进行调用. 低频操作  
  
2、数据库使用GPU时, 发给GPU的数据最多有多少?  
- 不能超过模型能处理的上下文, 例如一般是128K(参数量相同的情况下上下文支持越大的模型, 回复精确度越低), 目前最大的可能是1MB.    
- 通常发给大模型的数据不会太大. 可能在KB级别.     
  
如果数据库的带宽是10GB, 每秒可以向GPU发送131万次请求(每个请求1KB). 显然这样的请求量, GPU早就成为瓶颈了. 一定不会是数据库的传输带宽, move data更便宜.    
  
3、数据库服务器升级/更换GPU时, 需要停止该服务器上运行的数据库吗?  
- 肯定影响啊, 为了降低影响, 至少得切换吧?  
  
4、企业中除了数据库要用GPU, 还有哪些应用需要使用GPU, 相比于数据库, 这些应用使用GPU的频率更高还是更低?   
- 大概率是面向C端/AI Agent的应用使用GPU更高频. 在数据库服务器中安装GPU卡, 增加了数据库集群的故障点.    
  
5、数据库服务器需要额外的空间来存储模型吗?  
- 当然需要, 因为使用大模型时, 需要把模型参数全部加在到GPU内存中. (模型有大有小, deepseek R1 671B参数量化后还需要400多GB. 如果你希望使用各种不同的模型, 则需要在数据库服务器上预留更多的存储空间来存放模型, 到时候切换模型还会导致瞬间的占用存储模型文件的磁盘IO, 也可能影响数据库稳定性).  
  
综上, 数据库服务器集成GPU一定不是好主意.  
  
其实数据库要的是大模型的推理能力, 集成GPU不是目的, 而是手段. 正确的做法一定是建立独立的GPU服务器集群, 让数据库使用API调用大模型的能力.    
  
所以`postgresml`这个项目的价值不是它集成了GPU(个人认为这个反而是败笔), 有价值的实际上是“数据库与大模型在能力上的结合对业务和数据产生了新的价值”.  
  
https://postgresml.org/docs/  
  
https://github.com/postgresml/postgresml  
  
https://www.star-history.com/#postgresml/postgresml&Date  
  
## 数据库到底要提升什么能力?来更好的结合AI?   
个人观点:  
  
1、wire protocol的改进.   
  
GPU服务器集群可以部署更大参数量、更多的模型, 算力将大幅提升, 同时上下文的能力未来也可能会有大幅提升.  
  
所以一次SQL请求中从数据库提取大量数据还是有可能的. 所以要在wire protocol这块下功夫:   
- 避免序列号反序列化, 数据直达模型   
- 协议层传输加密/压缩能力   
- 更高效的支持mcp(resource/tools/prompt)   
- random URL+token支持. 例如, 在数据库中生成SQL对应的URL和相应token, 在一个时间窗口内(例如30秒), 可以直接通过这个url (例如( `protocol://url/parameter:$?&token:$?` ) ) 访问对应数据库获取相应数据. 结合mcp server, 这就让AI agent可以更高效的从数据库中访问需要的数据.      
  
2、内置调用大模型API的异步函数接口  
- 因为大模型的请求通常都比较长, 通过接口异步化, 可以把请求提前, 可以使用并发, 可以提高整体数据库吞吐. 和PostgreSQL 18的AIO优化一个思路.   
  
  
